{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11038a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "  0: \"ë³´ë ¹ë¶€ìŠ¤íŒŒì • 5mg\"\n",
      "  1: \"ë®¤í…Œë€ìº¡ìŠ 100mg\"\n",
      "  2: \"ì¼ì–‘í•˜ì´íŠ¸ë¦°ì • 2mg\"\n",
      "  3: \"ê¸°ë„¥ì‹ ì—í”„ì •(ì€í–‰ì—½ì—‘ìŠ¤)(ìˆ˜ì¶œìš©)\"\n",
      "  4: \"ë¬´ì½”ìŠ¤íƒ€ì •(ë ˆë°”ë¯¸í”¼ë“œ)(ë¹„ë§¤í’ˆ)\"\n",
      "  5: \"ì•Œë“œë¦°ì •\"\n",
      "  6: \"ë‰´ë¡œë©”ë“œì •(ì˜¥ì‹œë¼ì„¸íƒ)\"\n",
      "  7: \"íƒ€ì´ë ˆë†€ì •500mg\"\n",
      "  8: \"ì—ì–´íƒˆì •(ì•„ì„¸í´ë¡œí˜ë‚™)\"\n",
      "  9: \"ì‚¼ë‚¨ê±´ì¡°ìˆ˜ì‚°í™”ì•Œë£¨ë¯¸ëŠ„ê²”ì •\"\n",
      "  10: \"íƒ€ì´ë ˆë†€ì´ì•Œì„œë°©ì •(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)(ìˆ˜ì¶œìš©)\"\n",
      "  11: \"ì‚ì½¤ì”¨ì—í”„ì • 618.6mg/ë³‘\"\n",
      "  12: \"ì¡°ì¸ìŠ¤ì • 200mg\"\n",
      "  13: \"ì„ë¡œì¼ˆì • 100mg\"\n",
      "  14: \"ë¦¬ë ‰ìŠ¤íœì • 300mg/PTP\"\n",
      "  15: \"ì•„ë¹Œë¦¬íŒŒì´ì • 10mg\"\n",
      "  16: \"ìì´í”„ë ‰ì‚¬ì • 2.5mg\"\n",
      "  17: \"ë‹¤ë³´íƒ€ë¯¼íì • 10mg/ë³‘\"\n",
      "  18: \"ì¨ìŠ¤íœ8ì‹œê°„ì´ì•Œì„œë°©ì • 650mg\"\n",
      "  19: \"ì—ë¹…ì‚¬ì •(ë©”ë§Œí‹´ì—¼ì‚°ì—¼)(ë¹„ë§¤í’ˆ)\"\n",
      "  20: \"ë¦¬í”¼í† ì • 20mg\"\n",
      "  21: \"í¬ë ˆìŠ¤í† ì • 20mg\"\n",
      "  22: \"ê°€ë°”í† íŒŒì • 100mg\"\n",
      "  23: \"ë™ì•„ê°€ë°”íœí‹´ì • 800mg\"\n",
      "  24: \"ì˜¤ë§ˆì½”ì—°ì§ˆìº¡ìŠ(ì˜¤ë©”ê°€-3-ì‚°ì—í‹¸ì—ìŠ¤í…Œë¥´90)\"\n",
      "  25: \"ë€ìŠ¤í†¤ì—˜ì—í”„ë””í‹°ì • 30mg\"\n",
      "  26: \"ë¦¬ë¦¬ì¹´ìº¡ìŠ 150mg\"\n",
      "  27: \"ì¢…ê·¼ë‹¹ê¸€ë¦¬ì•„í‹°ë¦°ì—°ì§ˆìº¡ìŠ(ì½œë¦°ì•Œí¬ì„¸ë ˆì´íŠ¸)\"\n",
      "  28: \"ì½œë¦¬ë„¤ì´íŠ¸ì—°ì§ˆìº¡ìŠ 400mg\"\n",
      "  29: \"íŠ¸ë£¨ë¹„íƒ€ì • 60mg/ë³‘\"\n",
      "  30: \"ìŠ¤í† ê°€ì • 10mg\"\n",
      "  31: \"ë…¸ë°”ìŠ¤í¬ì • 5mg\"\n",
      "  32: \"ë§ˆë„íŒŒì •\"\n",
      "  33: \"í”Œë¼ë¹…ìŠ¤ì • 75mg\"\n",
      "  34: \"ì—‘ìŠ¤í¬ì§€ì • 5/160mg\"\n",
      "  35: \"í ë£¨ë¹„ì •(í ë£¨ë¹„í”„ë¡œíœ)\"\n",
      "  36: \"ì•„í† ë¥´ë°”ì • 10mg\"\n",
      "  37: \"ë¼ë¹„ì—íŠ¸ì • 20mg\"\n",
      "  38: \"ë¦¬í”¼ë¡œìš°ì • 20mg\"\n",
      "  39: \"ìëˆ„ë¹„ì•„ì • 50mg\"\n",
      "  40: \"ë§¥ì‹œë¶€íœì´ì•Œì • 300mg\"\n",
      "  41: \"ë©”ê°€íŒŒì›Œì • 90mg/ë³‘\"\n",
      "  42: \"ì¿ ì—íƒ€í•€ì • 25mg\"\n",
      "  43: \"ë¹„íƒ€ë¹„ë°±ì • 100mg/ë³‘\"\n",
      "  44: \"ë†€í…ì • 10mg\"\n",
      "  45: \"ìëˆ„ë©”íŠ¸ì • 50/850mg\"\n",
      "  46: \"íì‹œë“œì • 31.5mg/PTP\"\n",
      "  47: \"ì•„ëª¨ì˜íƒ„ì • 5/100mg\"\n",
      "  48: \"ì„¸ë¹„ì¹´ì • 10/40mg\"\n",
      "  49: \"íŠ¸ìœˆìŠ¤íƒ€ì • 40/5mg\"\n",
      "  50: \"ì¹´ë‚˜ë¸Œì • 60mg\"\n",
      "  51: \"ìš¸íŠ¸ë¼ì…‹ì´ì•Œì„œë°©ì •\"\n",
      "  52: \"ì¡¸ë¡œí‘¸íŠ¸ì • 100mg\"\n",
      "  53: \"íŠ¸ë¼ì  íƒ€ì •(ë¦¬ë‚˜ê¸€ë¦½í‹´)\"\n",
      "  54: \"ë¹„ëª¨ë³´ì • 500/20mg\"\n",
      "  55: \"ë ˆì¼ë¼ì •\"\n",
      "  56: \"ë¦¬ë°”ë¡œì • 4mg\"\n",
      "  57: \"ë ‰ì‚¬í”„ë¡œì • 15mg\"\n",
      "  58: \"íŠ¸ë¼ì  íƒ€ë“€ì˜¤ì • 2.5/850mg\"\n",
      "  59: \"ë‚™ì†Œì¡¸ì • 500/20mg\"\n",
      "  60: \"ì•„ì§ˆë ‰íŠ¸ì •(ë¼ì‚¬ê¸¸ë¦°ë©”ì‹¤ì‚°ì—¼)\"\n",
      "  61: \"ìëˆ„ë©”íŠ¸ì—‘ìŠ¤ì•Œì„œë°©ì • 100/1000mg\"\n",
      "  62: \"ê¸€ë¦¬ì•„íƒ€ë¯¼ì—°ì§ˆìº¡ìŠ\"\n",
      "  63: \"ì‹ ë°”ë¡œì •\"\n",
      "  64: \"ì—ìŠ¤ì›ì— í”„ì • 20mg\"\n",
      "  65: \"ë¸Œë¦°í…”ë¦­ìŠ¤ì • 20mg\"\n",
      "  66: \"ê¸€ë¦¬í‹´ì •(ì½œë¦°ì•Œí¬ì„¸ë ˆì´íŠ¸)\"\n",
      "  67: \"ì œë¯¸ë©”íŠ¸ì„œë°©ì • 50/1000mg\"\n",
      "  68: \"ì•„í† ì ¯ì • 10/40mg\"\n",
      "  69: \"ë¡œìˆ˜ì ¯ì •10/5ë°€ë¦¬ê·¸ë¨\"\n",
      "  70: \"ë¡œìˆ˜ë°”ë¯¸ë¸Œì • 10/20mg\"\n",
      "  71: \"ì¹´ë°œë¦°ìº¡ìŠ 25mg\"\n",
      "  72: \"ì¼€ì´ìº¡ì • 50mg\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "mapping_path = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_mapping.csv\"\n",
    "\n",
    "# CSV ë¡œë“œ\n",
    "df = pd.read_csv(mapping_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# class_id, categories_name ì»¬ëŸ¼ë§Œ ì‚¬ìš©\n",
    "if not {\"class_id\", \"categories_name\"}.issubset(df.columns):\n",
    "    raise ValueError(\"âŒ yolo_mapping.csvì— 'class_id' ë˜ëŠ” 'categories_name' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì •ë ¬ (class_id ê¸°ì¤€)\n",
    "df = df.sort_values(by=\"class_id\").reset_index(drop=True)\n",
    "\n",
    "# YAML í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "print(\"names:\")\n",
    "for _, row in df.iterrows():\n",
    "    class_id = int(row[\"class_id\"])\n",
    "    name = str(row[\"categories_name\"]).strip().replace('\"', \"'\")  # í°ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„\n",
    "    print(f\"  {class_id}: \\\"{name}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31032455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YOLO í¬ë§· ë¼ë²¨ íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration\n",
      "ì´ ìƒì„±ëœ íŒŒì¼ ìˆ˜: 1489\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------\n",
    "annotations_csv = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/project_annotations.csv\"\n",
    "mapping_csv     = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_mapping.csv\"\n",
    "output_dir      = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2ï¸âƒ£ í´ë” ì¤€ë¹„\n",
    "# ------------------------------------------------------\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------\n",
    "ann_df = pd.read_csv(annotations_csv)\n",
    "map_df = pd.read_csv(mapping_csv)\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "ann_df[\"dl_idx\"] = ann_df[\"dl_idx\"].astype(str).str.strip()\n",
    "map_df[\"categories_id\"] = map_df[\"categories_id\"].astype(str).str.strip()\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4ï¸âƒ£ dl_idx â†’ class_id ë§¤í•‘\n",
    "# ------------------------------------------------------\n",
    "merged = ann_df.merge(\n",
    "    map_df[[\"categories_id\", \"class_id\"]],\n",
    "    left_on=\"dl_idx\",\n",
    "    right_on=\"categories_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5ï¸âƒ£ YOLO í¬ë§· ë³€í™˜ í•¨ìˆ˜\n",
    "# ------------------------------------------------------\n",
    "def bbox_to_yolo(bbox, img_w, img_h):\n",
    "    try:\n",
    "        x, y, w, h = [float(v) for v in bbox.strip(\"[]\").split(\",\")]\n",
    "    except Exception:\n",
    "        return None  # ì˜ëª»ëœ bboxëŠ” ê±´ë„ˆëœ€\n",
    "\n",
    "    x_center = (x + w / 2) / img_w\n",
    "    y_center = (y + h / 2) / img_h\n",
    "    w_norm = w / img_w\n",
    "    h_norm = h / img_h\n",
    "    return x_center, y_center, w_norm, h_norm\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6ï¸âƒ£ íŒŒì¼ ë‹¨ìœ„ë¡œ YOLO txt ìƒì„±\n",
    "# ------------------------------------------------------\n",
    "for file_name, group in merged.groupby(\"file_name\"):\n",
    "    label_lines = []\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        bbox_str = str(row[\"bbox\"])\n",
    "        result = bbox_to_yolo(bbox_str, row[\"width\"], row[\"height\"])\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        x_center, y_center, w_norm, h_norm = result\n",
    "        class_id = int(row[\"class_id\"])\n",
    "        label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "\n",
    "    # ë¼ë²¨ íŒŒì¼ ì €ì¥\n",
    "    label_path = os.path.join(output_dir, os.path.splitext(file_name)[0] + \".txt\")\n",
    "    with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "print(f\"âœ… YOLO í¬ë§· ë¼ë²¨ íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ {output_dir}\")\n",
    "print(f\"ì´ ìƒì„±ëœ íŒŒì¼ ìˆ˜: {len(merged['file_name'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3d799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YOLO í¬ë§· ë¼ë²¨ íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration\n",
      "ì´ ìƒì„±ëœ ë¼ë²¨ íŒŒì¼ ìˆ˜: 2265\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------\n",
    "annotations_csv = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/augmented_dlidx_samples.csv\"\n",
    "mapping_csv     = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_mapping.csv\"\n",
    "output_dir      = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2ï¸âƒ£ ì¶œë ¥ í´ë” ì¤€ë¹„\n",
    "# ------------------------------------------------------\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------------------------------\n",
    "ann_df = pd.read_csv(annotations_csv)\n",
    "map_df = pd.read_csv(mapping_csv)\n",
    "\n",
    "# ë¬¸ìì—´ ì •ë¦¬\n",
    "ann_df[\"dl_idx\"] = ann_df[\"dl_idx\"].astype(str).str.strip()\n",
    "map_df[\"categories_id\"] = map_df[\"categories_id\"].astype(str).str.strip()\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4ï¸âƒ£ dl_idx â†’ class_id ë§¤í•‘\n",
    "# ------------------------------------------------------\n",
    "merged = ann_df.merge(\n",
    "    map_df[[\"categories_id\", \"class_id\"]],\n",
    "    left_on=\"dl_idx\",\n",
    "    right_on=\"categories_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5ï¸âƒ£ bbox ë¬¸ìì—´ íŒŒì‹± â†’ YOLO ì •ê·œí™” ì¢Œí‘œ ë³€í™˜\n",
    "# ------------------------------------------------------\n",
    "def bbox_to_yolo(bbox, img_w, img_h):\n",
    "    \"\"\"\n",
    "    COCO í˜•ì‹ [x, y, w, h] â†’ YOLO ì •ê·œí™” ì¢Œí‘œë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # bbox ë¬¸ìì—´ \"[100.5, 200.2, 50.0, 30.0]\" â†’ ìˆ«ì ë¦¬ìŠ¤íŠ¸\n",
    "        if isinstance(bbox, str):\n",
    "            bbox = bbox.strip(\"[]\").split(\",\")\n",
    "        bbox = [float(v) for v in bbox]\n",
    "        if len(bbox) != 4:\n",
    "            return None\n",
    "        x, y, w, h = bbox\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # ì •ê·œí™” ë³€í™˜\n",
    "    x_center = (x + w / 2) / img_w\n",
    "    y_center = (y + h / 2) / img_h\n",
    "    w_norm = w / img_w\n",
    "    h_norm = h / img_h\n",
    "\n",
    "    return x_center, y_center, w_norm, h_norm\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6ï¸âƒ£ YOLO txt íŒŒì¼ ìƒì„±\n",
    "# ------------------------------------------------------\n",
    "for file_name, group in merged.groupby(\"file_name\"):\n",
    "    label_lines = []\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        bbox = row[\"bbox\"]\n",
    "        result = bbox_to_yolo(bbox, row[\"width\"], row[\"height\"])\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        x_center, y_center, w_norm, h_norm = result\n",
    "        class_id = int(row[\"class_id\"])\n",
    "        label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "\n",
    "    # íŒŒì¼ ì €ì¥\n",
    "    label_path = os.path.join(output_dir, os.path.splitext(file_name)[0] + \".txt\")\n",
    "    with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "print(f\"âœ… YOLO í¬ë§· ë¼ë²¨ íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ {output_dir}\")\n",
    "print(f\"ì´ ìƒì„±ëœ ë¼ë²¨ íŒŒì¼ ìˆ˜: {len(merged['file_name'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c736cc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 8137ê°œ ë¼ë²¨ í•­ëª© ì¶”ì¶œ ì™„ë£Œ.\n",
      "                                          file_name  class_id\n",
      "0  K-003743-005886-012778-038954_0_2_0_2_90_000_200        10\n",
      "1  K-003743-005886-012778-038954_0_2_0_2_90_000_200        17\n",
      "2  K-003483-016232-027777-034597_0_2_0_2_90_000_200        50\n",
      "3  K-003483-016232-027777-034597_0_2_0_2_90_000_200        67\n",
      "4  K-003483-016232-027777-034597_0_2_0_2_90_000_200        20\n",
      "5  K-003483-016232-027777-034597_0_2_0_2_90_000_200         3\n",
      "6  K-003483-020877-025367-036637_0_2_0_2_70_000_200        69\n",
      "7  K-003483-020877-025367-036637_0_2_0_2_70_000_200        34\n",
      "8  K-003483-020877-025367-036637_0_2_0_2_70_000_200        45\n",
      "9  K-003483-020877-025367-036637_0_2_0_2_70_000_200         3\n",
      "ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ â†’ /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration/yolo_label_integration_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------\n",
    "base_dir = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2ï¸âƒ£ txt íŒŒì¼ íƒìƒ‰ ë° class_id ì¶”ì¶œ\n",
    "# ------------------------------------------------------\n",
    "records = []\n",
    "\n",
    "for fname in os.listdir(base_dir):\n",
    "    if not fname.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    fpath = os.path.join(base_dir, fname)\n",
    "    base_name = os.path.splitext(fname)[0]  # í™•ì¥ì ì œì™¸ íŒŒì¼ëª…\n",
    "\n",
    "    try:\n",
    "        with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split()\n",
    "                class_id = parts[0]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ class_id\n",
    "                records.append({\n",
    "                    \"file_name\": base_name,\n",
    "                    \"class_id\": int(class_id)\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {fname}: {e}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3ï¸âƒ£ DataFrame ìƒì„±\n",
    "# ------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4ï¸âƒ£ ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥\n",
    "# ------------------------------------------------------\n",
    "print(f\"âœ… ì´ {len(df)}ê°œ ë¼ë²¨ í•­ëª© ì¶”ì¶œ ì™„ë£Œ.\")\n",
    "print(df.head(10))\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "output_path = os.path.join(base_dir, \"yolo_label_integration_summary.csv\")\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ â†’ {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f01f8a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train: 7306, val: 7331, test: 806\n",
      "ğŸ“¦ train ì„¸íŠ¸: 3380ê°œ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ â†’ /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/labels/train\n",
      "ğŸ“¦ val ì„¸íŠ¸: 3380ê°œ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ â†’ /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/labels/val\n",
      "ğŸ“¦ test ì„¸íŠ¸: 374ê°œ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ â†’ /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/labels/test\n",
      "\n",
      "ğŸ¯ YOLO ë¼ë²¨ ë¶„í•  ë° ë³µì‚¬ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------\n",
    "src_dir = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/yolo_label_integration\"\n",
    "dst_root = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/labels\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2ï¸âƒ£ CSV ë¡œë“œ (ì´ì „ ë‹¨ê³„ì—ì„œ ë§Œë“  summary)\n",
    "# ------------------------------------------------------\n",
    "csv_path = os.path.join(src_dir, \"yolo_label_integration_summary.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
    "assert {\"file_name\", \"class_id\"}.issubset(df.columns), \"file_name / class_id ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3ï¸âƒ£ StratifiedGroupKFold ì‚¬ìš©\n",
    "#     - class_id ë¹„ìœ¨ ìœ ì§€\n",
    "#     - file_name ë‹¨ìœ„ë¡œ ë¶„í•  (ê°™ì€ ì´ë¯¸ì§€ê°€ ë‹¤ë¥¸ splitì— ì•ˆ ë“¤ì–´ê°€ë„ë¡)\n",
    "# ------------------------------------------------------\n",
    "df[\"file_name\"] = df[\"file_name\"].astype(str)\n",
    "\n",
    "# ê·¸ë£¹ ë‹¨ìœ„ ë¶„í• ì„ ìœ„í•œ unique file list ìƒì„±\n",
    "groups = df[\"file_name\"]\n",
    "y = df[\"class_id\"]\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "splits = list(sgkf.split(df, y, groups))\n",
    "# 8:1:1 ë¹„ìœ¨ -> ì²« 8, ë‹¤ìŒ 1, ë§ˆì§€ë§‰ 1 split ì‚¬ìš©\n",
    "train_idx, temp_idx = splits[0]  # ì²« ë²ˆì§¸ 10ê°œ fold ì¤‘ í•˜ë‚˜ë¥¼ train\n",
    "val_idx, test_idx = splits[1]    # ë‹¤ìŒ 2ê°œ foldë¡œ val, test\n",
    "\n",
    "# train, val, test DataFrame ë¶„ë¦¬\n",
    "train_df = df.iloc[train_idx]\n",
    "val_df = df.iloc[val_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "print(f\"âœ… train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4ï¸âƒ£ í´ë” êµ¬ì¡° ìƒì„±\n",
    "# ------------------------------------------------------\n",
    "for sub in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(dst_root, sub), exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5ï¸âƒ£ íŒŒì¼ ë³µì‚¬ í•¨ìˆ˜ ì •ì˜\n",
    "# ------------------------------------------------------\n",
    "def copy_files(file_list, subset_name):\n",
    "    dst_dir = os.path.join(dst_root, subset_name)\n",
    "    copied = 0\n",
    "    for fname in file_list:\n",
    "        src_path = os.path.join(src_dir, f\"{fname}.txt\")\n",
    "        dst_path = os.path.join(dst_dir, f\"{fname}.txt\")\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            copied += 1\n",
    "    print(f\"ğŸ“¦ {subset_name} ì„¸íŠ¸: {copied}ê°œ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ â†’ {dst_dir}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6ï¸âƒ£ ì‹¤ì œ ë³µì‚¬ ìˆ˜í–‰\n",
    "# ------------------------------------------------------\n",
    "copy_files(train_df[\"file_name\"].unique(), \"train\")\n",
    "copy_files(val_df[\"file_name\"].unique(), \"val\")\n",
    "copy_files(test_df[\"file_name\"].unique(), \"test\")\n",
    "\n",
    "print(\"\\nğŸ¯ YOLO ë¼ë²¨ ë¶„í•  ë° ë³µì‚¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55371884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ TRAIN ì„¸íŠ¸ â†’ ë³µì‚¬: 3371ê°œ / ëˆ„ë½: 0ê°œ / ë¼ë²¨ì‚­ì œ: 0ê°œ\n",
      "ğŸ“¦ VAL ì„¸íŠ¸ â†’ ë³µì‚¬: 3375ê°œ / ëˆ„ë½: 0ê°œ / ë¼ë²¨ì‚­ì œ: 0ê°œ\n",
      "ğŸ“¦ TEST ì„¸íŠ¸ â†’ ë³µì‚¬: 370ê°œ / ëˆ„ë½: 0ê°œ / ë¼ë²¨ì‚­ì œ: 0ê°œ\n",
      "\n",
      "âœ… ì´ë¯¸ì§€ ë³µì‚¬ ë° ì •ë¦¬ ì™„ë£Œ!\n",
      "ğŸªµ ë¡œê·¸ íŒŒì¼ ì €ì¥ ìœ„ì¹˜: /Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/missing_images.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# ------------------------------------------------------\n",
    "label_root = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/labels\"\n",
    "src_image_dirs = [\n",
    "    \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/add/images\",\n",
    "    \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/1_project/train_images\",\n",
    "]\n",
    "dst_image_root = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/images\"\n",
    "log_path = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/missing_images.log\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë¡œê·¸íŒŒì¼ ì´ˆê¸°í™”\n",
    "# ------------------------------------------------------\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as logf:\n",
    "    logf.write(\"ğŸš« ëˆ„ë½ëœ ì´ë¯¸ì§€ ë° ì‚­ì œëœ ë¼ë²¨ ëª©ë¡\\n\\n\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3ï¸âƒ£ ë¶„í•  í´ë” ìˆœíšŒ (train, val, test)\n",
    "# ------------------------------------------------------\n",
    "for subset in [\"train\", \"val\", \"test\"]:\n",
    "    label_dir = os.path.join(label_root, subset)\n",
    "    dst_dir = os.path.join(dst_image_root, subset)\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    txt_files = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "    missing_count = 0\n",
    "    copied_count = 0\n",
    "    deleted_labels = 0\n",
    "\n",
    "    for txt in txt_files:\n",
    "        base_name = os.path.splitext(txt)[0]\n",
    "        dst_path = os.path.join(dst_dir, f\"{base_name}.png\")\n",
    "        txt_path = os.path.join(label_dir, txt)\n",
    "\n",
    "        # ë‘ ê°œì˜ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë³µì‚¬\n",
    "        found = False\n",
    "        for src_dir in src_image_dirs:\n",
    "            src_path = os.path.join(src_dir, f\"{base_name}.png\")\n",
    "            if os.path.exists(src_path):\n",
    "                shutil.copy(src_path, dst_path)\n",
    "                copied_count += 1\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            missing_count += 1\n",
    "            # ë¼ë²¨(txt) ì‚­ì œ\n",
    "            if os.path.exists(txt_path):\n",
    "                os.remove(txt_path)\n",
    "                deleted_labels += 1\n",
    "            with open(log_path, \"a\", encoding=\"utf-8\") as logf:\n",
    "                logf.write(f\"[{subset}] {base_name}.png ì—†ìŒ â†’ ë¼ë²¨ ì‚­ì œë¨: {txt_path}\\n\")\n",
    "\n",
    "    print(f\"ğŸ“¦ {subset.upper()} ì„¸íŠ¸ â†’ ë³µì‚¬: {copied_count}ê°œ / ëˆ„ë½: {missing_count}ê°œ / ë¼ë²¨ì‚­ì œ: {deleted_labels}ê°œ\")\n",
    "\n",
    "print(\"\\nâœ… ì´ë¯¸ì§€ ë³µì‚¬ ë° ì •ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"ğŸªµ ë¡œê·¸ íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02fd4da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë³€í™˜ ì¤‘: train\n",
      "ğŸ“‚ ë³€í™˜ ì¤‘: val\n",
      "ğŸ“‚ ë³€í™˜ ì¤‘: test\n",
      "\n",
      "âœ… ë³€í™˜ ì™„ë£Œ!\n",
      "ì´ ë¼ë²¨ íŒŒì¼ ìˆ˜: 7116\n",
      "ì •ê·œí™” ìˆ˜í–‰ëœ íŒŒì¼ ìˆ˜: 12\n"
     ]
    }
   ],
   "source": [
    "#ì´ë¯¸ì§€ ë°•ìŠ¤ ì •ê·œí™”\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# -------------------------------------------------------\n",
    "# YOLO ë¼ë²¨ íŒŒì¼ í´ë” ê²½ë¡œ\n",
    "label_root = \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/2_yolo/labels\"\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ì´ ì €ì¥ëœ ê²½ë¡œë“¤ (ì›ë³¸ ë˜ëŠ” add í´ë”)\n",
    "image_roots = [\n",
    "    \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/data/add/images\",\n",
    "    \"/Users/apple/Documents/ai_engineer/Tablet-Detection-with-Object-Detection/dataset/1_project/train_images\"\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë³´ì¡° í•¨ìˆ˜ â€” ì´ë¯¸ì§€ í¬ê¸° íƒìƒ‰\n",
    "# -------------------------------------------------------\n",
    "def find_image_size(base_name):\n",
    "    \"\"\"ë¼ë²¨ ì´ë¦„(base_name)ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ì˜ (width, height)ë¥¼ ë°˜í™˜\"\"\"\n",
    "    for root in image_roots:\n",
    "        for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "            img_path = os.path.join(root, f\"{base_name}{ext}\")\n",
    "            if os.path.exists(img_path):\n",
    "                with Image.open(img_path) as img:\n",
    "                    return img.size  # (width, height)\n",
    "    return None\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3ï¸âƒ£ ì •ê·œí™” í•¨ìˆ˜\n",
    "# -------------------------------------------------------\n",
    "def normalize_bbox(xc, yc, w, h, img_w, img_h):\n",
    "    \"\"\"í”½ì…€ ë‹¨ìœ„ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”\"\"\"\n",
    "    return xc / img_w, yc / img_h, w / img_w, h / img_h\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4ï¸âƒ£ ë¼ë²¨ íŒŒì¼ ìˆœíšŒ ë° ë³€í™˜\n",
    "# -------------------------------------------------------\n",
    "count_total = 0\n",
    "count_converted = 0\n",
    "missing_images = []\n",
    "\n",
    "for subset in [\"train\", \"val\", \"test\"]:\n",
    "    label_dir = os.path.join(label_root, subset)\n",
    "    if not os.path.exists(label_dir):\n",
    "        continue\n",
    "\n",
    "    print(f\"ğŸ“‚ ë³€í™˜ ì¤‘: {subset}\")\n",
    "    for txt_file in os.listdir(label_dir):\n",
    "        if not txt_file.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        base_name = os.path.splitext(txt_file)[0]\n",
    "        label_path = os.path.join(label_dir, txt_file)\n",
    "        img_size = find_image_size(base_name)\n",
    "        count_total += 1\n",
    "\n",
    "        if img_size is None:\n",
    "            missing_images.append(base_name)\n",
    "            continue\n",
    "\n",
    "        img_w, img_h = img_size\n",
    "        new_lines = []\n",
    "\n",
    "        with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "\n",
    "                cls_id, xc, yc, w, h = parts\n",
    "                # float ë³€í™˜\n",
    "                xc, yc, w, h = map(float, [xc, yc, w, h])\n",
    "\n",
    "                # ê°’ì´ 1ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ì •ê·œí™” í•„ìš”\n",
    "                if xc > 1 or yc > 1 or w > 1 or h > 1:\n",
    "                    xc, yc, w, h = normalize_bbox(xc, yc, w, h, img_w, img_h)\n",
    "                    count_converted += 1\n",
    "\n",
    "                new_lines.append(f\"{cls_id} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "        # ë³€í™˜ ê²°ê³¼ë¥¼ ê°™ì€ íŒŒì¼ì— overwrite\n",
    "        with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
    "\n",
    "print(\"\\nâœ… ë³€í™˜ ì™„ë£Œ!\")\n",
    "print(f\"ì´ ë¼ë²¨ íŒŒì¼ ìˆ˜: {count_total}\")\n",
    "print(f\"ì •ê·œí™” ìˆ˜í–‰ëœ íŒŒì¼ ìˆ˜: {count_converted}\")\n",
    "if missing_images:\n",
    "    print(f\"âš ï¸ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ë¼ë²¨ íŒŒì¼: {len(missing_images)}ê°œ\")\n",
    "    print(\"\\n\".join(missing_images[:10]), \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2caef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_team6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
