import os
import random
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

from src.config import load_config

config = load_config()  # ../../config.yamlì„ ìë™ìœ¼ë¡œ ì½ìŒ
train_ratio = config["dataset"]["train_ratio"]
batch_size = config["dataset"]["batch_size"]
seed = config["project"]["seed"]


# ==========================================================
# 1ï¸. Seed ê³ ì • í•¨ìˆ˜
# ==========================================================
def set_global_seed(seed=seed):
    """ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"===========lobal seed fixed to {seed}===========")


# ==========================================================
# 2. Worker seed ê³ ì • (DataLoader ë‚´ë¶€ìš©)
# ==========================================================
def seed_worker(worker_id):
    """DataLoaderì˜ ê° workerì˜ ë‚œìˆ˜ ì‹œë“œë¥¼ ê³ ì •"""
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


# ==========================================================
# 3. Stratified Split í•¨ìˆ˜
# ==========================================================
def stratified_split_by_category(df, train_ratio=0.8, seed=42):
    """categories_id ë¹„ìœ¨ì„ ê³ ë ¤í•˜ì—¬ train/test ë¶„í•  (object ë‹¨ìœ„)"""
    np.random.seed(seed)
    train_list, test_list = [], []

    for cat_id, group in df.groupby("categories_id"):
        n_total = len(group)
        n_train = int(n_total * train_ratio)
        indices = np.random.permutation(group.index)
        train_idx = indices[:n_train]
        test_idx = indices[n_train:]
        train_list.append(df.loc[train_idx])
        test_list.append(df.loc[test_idx])

    train_df = pd.concat(train_list).reset_index(drop=True)
    test_df = pd.concat(test_list).reset_index(drop=True)

    print(f"===========ë¶„ë¦¬ ì™„ë£Œ (seed={seed}): Train {len(train_df)}ê°œ / Test {len(test_df)}ê°œ===========")
    return train_df, test_df


# ==========================================================
# 4. Albumentations Transform ì •ì˜
# ==========================================================
def get_train_transform():
    return A.Compose([
        A.Resize(640, 640),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.2),
        A.RandomBrightnessContrast(p=0.3),
        A.HueSaturationValue(p=0.3),
        A.RandomRotate90(p=0.2),
        A.Normalize(mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))


def get_test_transform():
    return A.Compose([
        A.Resize(640, 640),
        A.Normalize(mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))


# ==========================================================
# 5. Dataset í´ë˜ìŠ¤ ì •ì˜
# ==========================================================
class PillDataset(Dataset):
    def __init__(self, df, image_dir, transform=None):
        self.df = df
        self.image_dir = image_dir
        self.transform = transform
        self.grouped = df.groupby("images_file_name")
        self.image_names = list(self.grouped.groups.keys())

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        image_name = self.image_names[idx]
        records = self.grouped.get_group(image_name)
        image_path = os.path.join(self.image_dir, image_name)
        image = np.array(Image.open(image_path).convert("RGB"))

        bboxes, labels = [], []
        for _, row in records.iterrows():
            x1, y1 = row["bbox_x"], row["bbox_y"]
            x2, y2 = x1 + row["bbox_w"], y1 + row["bbox_h"]
            bboxes.append([x1, y1, x2, y2])
            labels.append(row["categories_name"])

        if self.transform:
            transformed = self.transform(image=image, bboxes=bboxes, class_labels=labels)
            image = transformed["image"]
            bboxes = transformed["bboxes"]
            labels = transformed["class_labels"]

        target = {
            "boxes": torch.tensor(bboxes, dtype=torch.float32),
            "labels": labels
        }
        return image, target


# ==========================================================
# 6. DataLoader ìƒì„± í•¨ìˆ˜
# ==========================================================
def create_dataloaders(train_df, test_df, image_dir, batch_size= batch_size, num_workers=2, seed=seed):
    """train/test DataLoaderë¥¼ ìƒì„± (seed ê³ ì • í¬í•¨)"""
    set_global_seed(seed)
    g = torch.Generator()
    g.manual_seed(seed)

    train_dataset = PillDataset(train_df, image_dir, transform=get_train_transform())
    test_dataset = PillDataset(test_df, image_dir, transform=get_test_transform())

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        worker_init_fn=seed_worker,
        generator=g,
        collate_fn=lambda x: tuple(zip(*x))
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        worker_init_fn=seed_worker,
        generator=g,
        collate_fn=lambda x: tuple(zip(*x))
    )

    print(f"===========DataLoader ìƒì„± ì™„ë£Œ â†’ Train: {len(train_loader)} / Test: {len(test_loader)}===========")
    return train_loader, test_loader

# ==========================================================
# ğŸ”¹ Normalize ë³µì› í•¨ìˆ˜ (denormalization)
# ==========================================================
def denormalize_image(tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):
    """
    Normalizeëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì›ë˜ ìƒ‰ìƒìœ¼ë¡œ ë˜ëŒë¦¬ëŠ” í•¨ìˆ˜.
    Args:
        tensor (Tensor): [C, H, W]
        mean, std: Normalize ì‹œ ì‚¬ìš©í•œ ê°’
    Returns:
        np.ndarray: ë³µì›ëœ [H, W, C] ì´ë¯¸ì§€ (0~1 ë²”ìœ„)
    """
    img = tensor.clone().detach()
    for t, m, s in zip(img, mean, std):
        t.mul_(s).add_(m)
    img = img.permute(1, 2, 0).cpu().numpy()
    img = np.clip(img, 0, 1)
    return img


import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import torch
import os

def denormalize_image(tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):
    """Normalizeëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì›ë˜ ìƒ‰ìƒìœ¼ë¡œ ë˜ëŒë¦¼."""
    img = tensor.clone().detach()
    for t, m, s in zip(img, mean, std):
        t.mul_(s).add_(m)
    img = img.permute(1, 2, 0).cpu().numpy()
    return np.clip(img, 0, 1)


def visualize_loader_batch(
    data_loader,
    num_images=4,
    mean=(0.485, 0.456, 0.406),
    std=(0.229, 0.224, 0.225),
    normalize_applied=True,
    is_train=False,
    title_prefix=None,
    save_dir=None,
):
    """
    DataLoaderì˜ ë°°ì¹˜ ë‹¨ìœ„ ì‹œê°í™” (Normalize í•´ì œ + bbox í‘œì‹œ)

    Args:
        data_loader: PyTorch DataLoader
        num_images: í‘œì‹œí•  ì´ë¯¸ì§€ ìˆ˜
        mean, std: Normalize í•´ì œ ì‹œ ì‚¬ìš©
        normalize_applied: Normalize í•´ì œ ì—¬ë¶€
        is_train: Trueì´ë©´ 'Train' ì œëª©ìœ¼ë¡œ í‘œì‹œ
        title_prefix: ê° ì´ë¯¸ì§€ì˜ ì œëª© ì•ì— ë¶™ëŠ” ë¬¸ìì—´
        save_dir: ì§€ì • ì‹œ PNGë¡œ ì €ì¥
    """
    batch = next(iter(data_loader))
    images, targets = batch

    ncols = 2
    nrows = int(np.ceil(num_images / ncols))
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8 * ncols, 8 * nrows))
    axes = axes.flatten()

    for i in range(num_images):
        if i >= len(images):
            break

        img_tensor = images[i]
        if normalize_applied:
            img = denormalize_image(img_tensor, mean, std)
        else:
            img = img_tensor.permute(1, 2, 0).cpu().numpy()

        boxes = targets[i]["boxes"].cpu().numpy()
        labels = targets[i]["labels"]

        ax = axes[i]
        ax.imshow(img)
        colors = plt.cm.tab10.colors

        for j, box in enumerate(boxes):
            x1, y1, x2, y2 = box
            color = colors[j % len(colors)]
            rect = patches.Rectangle(
                (x1, y1),
                x2 - x1,
                y2 - y1,
                linewidth=2,
                edgecolor=color,
                facecolor="none",
            )
            ax.add_patch(rect)
            label_value = labels[j]
            # Tensorì¼ ê²½ìš° ìˆ«ì ì¶”ì¶œ
            if isinstance(label_value, torch.Tensor):
                label_value = int(label_value.item())

            ax.text(
                x1,
                y1 - 5,
                str(label_value),
                fontsize=9,
                color="white",
                backgroundcolor=color,
                fontweight="bold",
            )

        title = title_prefix or ("Train" if is_train else "Test")
        ax.set_title(f"{title} Image #{i}", fontsize=10)
        ax.axis("off")

    # ë‚¨ì€ subplot ë¹„í™œì„±í™”
    for k in range(i + 1, len(axes)):
        axes[k].axis("off")

    plt.tight_layout()

    if save_dir:
        os.makedirs(save_dir, exist_ok=True)
        filename = f"{title_prefix or ('train' if is_train else 'test')}_batch.png"
        path = os.path.join(save_dir, filename)
        plt.savefig(path, dpi=150)
        plt.close(fig)
        print(f"==========={title_prefix or ('Train' if is_train else 'Test')} ì‹œê°í™” ì €ì¥ ì™„ë£Œ â†’ {path}===========")
    else:
        plt.show()