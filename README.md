# Tablet-Detection-with-Object-Detection
| ëª¨ë¸ | ê³„ì—´ | ì •í™•ë„ (mAP@0.5) | ì†ë„ (FPS, RTX3060 ê¸°ì¤€) | íŠ¹ì§• ìš”ì•½ |
|:------|:------|:------:|:------:|:------|
| **VGGNet-16** | CNN Backbone | ğŸ”¹ **55 â€“ 60 %** | ğŸ¢ 20 â€“ 25 | ë‹¨ìˆœ êµ¬ì¡°, í•™ìŠµ ì•ˆì •ì ì´ì§€ë§Œ í‘œí˜„ë ¥ ë¶€ì¡± |
| **ResNet-50** | CNN Backbone | ğŸ”¹ **65 â€“ 70 %** | âš¡ 45 â€“ 50 | ê¸°ë³¸ ë°±ë³¸ìœ¼ë¡œ ìš°ìˆ˜, ìµœì‹  ëŒ€ë¹„ íš¨ìœ¨ ë‚®ìŒ |
| **YOLOv8** | 1-Stage Detector | ğŸ”¹ **78 â€“ 82 %** | âš¡ 70 + | ë§¤ìš° ë¹ ë¦„, ì‹¤ì‹œê°„ ì‘ìš© ì í•© |
| **YOLOv9** | 1-Stage Hybrid | ğŸ”¹ **85 â€“ 88 %** | âš¡ 60 + | NMS-free êµ¬ì¡°, ì •í™•ë„ í–¥ìƒ |
| **RT-DETR** | Transformer-based | ğŸ”¹ **90 â€“ 93 %** | âš¡ 40 â€“ 45 | YOLOê¸‰ ì†ë„ + DETRê¸‰ ì •ë°€ë„ |
| **Cascade R-CNN** | 2-Stage Detector | ğŸ”¹ **90 â€“ 92 %** | âš™ï¸ 15 â€“ 20 | Stage-wise ì •ë°€ ê²€ì¶œ, ì‘ì€ ê°ì²´ì— ê°•í•¨ |
| **ConvNeXt + Cascade R-CNN** | Hybrid CNN | ğŸ”¹ **92 â€“ 94 %** | âš™ï¸ 18 â€“ 20 | ìµœì‹  ë°±ë³¸ + ê³ ì •ë°€ íƒì§€, ì—°êµ¬/ì‚°ì—…ìš© ìµœê³  |
| **EfficientDet-D3** | Hybrid CNN | ğŸ”¹ **83 â€“ 87 %** | âš™ï¸ 30 â€“ 35 | ê²½ëŸ‰Â·íš¨ìœ¨ì , ì¤‘ê°„ê¸‰ ì •í™•ë„ |



| ëª¨ë¸ | ë…¼ë¬¸ ê³µì‹ URL | ê³µì‹ GitHub êµ¬í˜„ URL | PyTorch ê³µì‹ êµ¬í˜„ URL |
|------|---------------|----------------------|------------------------|
| **VGGNet-16** | [Very Deep Convolutional Networks for Large-Scale Image Recognition (arXiv:1409.1556)](https://arxiv.org/abs/1409.1556) | [Oxford VGG Group Research Page](https://www.robots.ox.ac.uk/~vgg/research/very_deep/) | [torchvision.models.vgg16](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.vgg16.html) |
| **ResNet-50** | [Deep Residual Learning for Image Recognition (arXiv:1512.03385)](https://arxiv.org/abs/1512.03385) | [Kaiming He: deep-residual-networks](https://github.com/KaimingHe/deep-residual-networks) | [torchvision.models.resnet50](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html) |
| **YOLOv8** | (ë…¼ë¬¸ ë¯¸ê³µê°œ, Ultralytics ë‚´ë¶€ ë¬¸ì„œ) | [Ultralytics YOLOv8 Repository](https://github.com/ultralytics/ultralytics) | [Ultralytics YOLO Docs](https://docs.ultralytics.com/models/yolov8) |
| **YOLOv9** | (ë¹„ê³µì‹ ë…¼ë¬¸ ë‹¨ê³„, Ultralytics ë¹„êµ ë¬¸ì„œ ì°¸ì¡°) | [Ultralytics YOLOv9 Info](https://docs.ultralytics.com/compare/efficientdet-vs-yolov9/) | â€” |
| **RT-DETR** | [DETRs Beat YOLOs on Real-time Object Detection (CVPR 2024)](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DETRs_Beat_YOLOs_on_Real-time_Object_Detection_CVPR_2024_paper.html) | [PaddlePaddle RT-DETR Repository](https://github.com/lyuwenyu/RT-DETR) | â€” |
| **Cascade R-CNN** | [Cascade R-CNN: Delving into High Quality Object Detection (arXiv:1906.09756)](https://arxiv.org/abs/1906.09756) | [Detectron Cascade R-CNN (official implementation)](https://github.com/zhaoweicai/Detectron-Cascade-RCNN) | [OpenMMLab MMDetection](https://github.com/open-mmlab/mmdetection) |
| **ConvNeXt + Cascade R-CNN** | [A ConvNet for the 2020s (arXiv:2201.03545)](https://arxiv.org/abs/2201.03545) + [Cascade R-CNN (arXiv:1906.09756)](https://arxiv.org/abs/1906.09756) | [ConvNeXt Official Repository](https://github.com/facebookresearch/ConvNeXt) + [MMDetection](https://github.com/open-mmlab/mmdetection) | [torchvision.models.convnext](https://pytorch.org/vision/main/models/generated/torchvision.models.convnext_base.html) |
| **EfficientDet-D3** | [EfficientDet: Scalable and Efficient Object Detection (CVPR 2020)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf) | [Yet-Another-EfficientDet-Pytorch](https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch) | â€” |